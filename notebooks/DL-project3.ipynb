{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11703048,"sourceType":"datasetVersion","datasetId":7345755}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Task 1: Baseline Model Evaluation\nThis section loads a pre‑trained ResNet‑34 model, prepares the TestDataSet with the same normalization used during training, and computes the model’s top‑1 and top‑5 accuracy on the original dataset. It sets the model to evaluation mode, iterates through the DataLoader, maps folder indices to true ImageNet labels, and reports the baseline performance.","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom tqdm import tqdm\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Load pre-trained ResNet-34 model\npretrained_model = torchvision.models.resnet34(weights='IMAGENET1K_V1')\npretrained_model = pretrained_model.to(device)\npretrained_model.eval()  # Switch to evaluation mode\n\n# Data preprocessing\nmean_norms = np.array([0.485, 0.456, 0.406])\nstd_norms  = np.array([0.229, 0.224, 0.225])\nplain_transforms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean_norms, std=std_norms)\n])\n\n# Update dataset path for Kaggle\ndataset_path = \"../input/testdataset/TestDataSet\"\ndataset = ImageFolder(root=dataset_path, transform=plain_transforms)\n\n# Create DataLoader\ndataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n\n# Load label mapping from JSON\nlabels_file = \"../input/testdataset/TestDataSet/labels_list.json\"\nwith open(labels_file, 'r') as f:\n    labels_map = json.load(f)\n\n# Parse label mapping into a dictionary: integer ID -> label name\nid_to_label = {}\nfor entry in labels_map:\n    idx, name = entry.split(\": \")\n    id_to_label[int(idx)] = name\n\n# Map folder index (0–99) to ImageNet ID (0–999)\nfolder_to_imagenet_id = {}\nfor idx, folder in enumerate(dataset.classes):\n    synset = os.path.basename(folder)\n    # Assume sorted synset keys correspond in order to folder indices\n    imagenet_id = list(id_to_label.keys())[idx]\n    folder_to_imagenet_id[idx] = imagenet_id\n\n# Define evaluation function for top-k accuracy\ndef evaluate_model(model, dataloader, device, top_k=(1, 5)):\n    model.eval()\n    correct = {k: 0 for k in top_k}\n    total = 0\n\n    with torch.no_grad():\n        for images, folder_labels in tqdm(dataloader):\n            images = images.to(device)\n            folder_labels = folder_labels.to(device)\n\n            # Convert folder index to actual ImageNet label\n            imagenet_labels = torch.tensor(\n                [folder_to_imagenet_id[int(fl)] for fl in folder_labels],\n                device=device\n            )\n\n            outputs = model(images)\n            # Compute top-k predictions\n            _, preds = outputs.topk(max(top_k), dim=1, largest=True, sorted=True)\n            preds = preds.t()\n\n            for k in top_k:\n                correct_k = preds[:k].eq(imagenet_labels.view(1, -1).expand_as(preds[:k]))\n                correct[k] += correct_k.reshape(-1).float().sum().item()\n\n            total += images.size(0)\n\n    # Calculate accuracy percentages\n    accuracy = {k: (correct[k] / total) * 100.0 for k in top_k}\n    return accuracy\n\n# Evaluate the original ResNet-34 model\nprint(\"Evaluating original ResNet-34 model...\")\naccuracy = evaluate_model(pretrained_model, dataloader, device, top_k=(1, 5))\n\n# Print results\nprint(\"ResNet-34 performance on the test dataset:\")\nprint(f\"Top-1 Accuracy: {accuracy[1]:.2f}%\")\nprint(f\"Top-5 Accuracy: {accuracy[5]:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T20:43:47.215430Z","iopub.execute_input":"2025-05-08T20:43:47.216277Z","iopub.status.idle":"2025-05-08T20:43:49.100855Z","shell.execute_reply.started":"2025-05-08T20:43:47.216249Z","shell.execute_reply":"2025-05-08T20:43:49.100063Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nEvaluating original ResNet-34 model...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 16/16 [00:01<00:00, 12.06it/s]","output_type":"stream"},{"name":"stdout","text":"ResNet-34 performance on the test dataset:\nTop-1 Accuracy: 76.00%\nTop-5 Accuracy: 94.20%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## Task 2: Single-Step FGSM Attack (L∞)\nHere we implement the Fast Gradient Sign Method (FGSM) to generate an **Adversarial Test Set 1**. For each input batch, we compute the gradient of the cross‑entropy loss with respect to the normalized image, add a perturbation of magnitude ε in the gradient’s sign direction, clamp the result to the valid pixel range, and evaluate how much the attack degrades the model’s top‑1 and top‑5 accuracy.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom tqdm import tqdm\n\n# --------- 1. FGSM attack function --------- #\ndef fgsm_attack(model, x, y, epsilon, clamp_min, clamp_max):\n    \"\"\"\n    Performs a single-step FGSM attack on a batch of inputs.\n\n    Parameters:\n    - model: the evaluation model\n    - x: input tensor batch, already normalized (shape=[B,3,224,224])\n    - y: corresponding true ImageNet labels (tensor shape=[B])\n    - epsilon: attack budget (maximum perturbation magnitude)\n    - clamp_min, clamp_max: per-channel lower/upper bounds in normalized space (tensor shape=[3,1,1])\n\n    Returns:\n    - A tensor of adversarial examples (shape=[B,3,224,224])\n    \"\"\"\n    x_adv = x.clone().detach().to(device)\n    x_adv.requires_grad = True\n\n    outputs = model(x_adv)\n    loss = nn.CrossEntropyLoss()(outputs, y)\n    model.zero_grad()\n    loss.backward()\n\n    # Add epsilon * sign(gradient) to the inputs\n    x_adv = x_adv + epsilon * x_adv.grad.sign()\n    # Clamp to the valid range\n    x_adv = torch.clamp(x_adv, clamp_min, clamp_max)\n\n    return x_adv.detach()\n\n# --------- 2. Precompute constants --------- #\nepsilon = 0.02  # attack budget\n\n# Normalization mean/std (must match Task 1)\nmean = torch.tensor([0.485, 0.456, 0.406], device=device).view(3, 1, 1)\nstd  = torch.tensor([0.229, 0.224, 0.225], device=device).view(3, 1, 1)\n\n# Ensure that after denormalization, pixel values fall in [0,1]\nclamp_min = (0.0 - mean) / std\nclamp_max = (1.0 - mean) / std\n\n# --------- 3. Generate adversarial samples for the entire test set --------- #\nadv_images_list = []\nadv_labels_list = []\n\npretrained_model.eval()\nfor images, folder_labels in tqdm(dataloader, desc=f\"FGSM Attack (ε={epsilon})\"):\n    images = images.to(device)\n    folder_labels = folder_labels.to(device)\n\n    # Convert folder index (0–99) to actual ImageNet label (0–999)\n    imagenet_labels = torch.tensor(\n        [folder_to_imagenet_id[int(idx)] for idx in folder_labels],\n        device=device\n    )\n\n    adv_batch = fgsm_attack(\n        pretrained_model,\n        images,\n        imagenet_labels,\n        epsilon,\n        clamp_min,\n        clamp_max\n    )\n\n    adv_images_list.append(adv_batch)\n    adv_labels_list.append(folder_labels)\n\n# Concatenate all batches and move to CPU\nadv_images_all = torch.cat(adv_images_list, dim=0).cpu()\nadv_labels_all = torch.cat(adv_labels_list, dim=0).cpu()\n\n# --------- 4. Build adversarial dataset and evaluate --------- #\nadv_dataset = TensorDataset(adv_images_all, adv_labels_all)\nadv_loader  = DataLoader(\n    adv_dataset,\n    batch_size=32,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True\n)\n\nadv_accuracy = evaluate_model(\n    pretrained_model,\n    adv_loader,\n    device,\n    top_k=(1, 5)\n)\n\nprint(f\"\\n=== Adversarial Test Set 1 (ε={epsilon}) ===\")\nprint(f\"Top-1 Accuracy: {adv_accuracy[1]:.2f}%\")\nprint(f\"Top-5 Accuracy: {adv_accuracy[5]:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T20:43:49.102313Z","iopub.execute_input":"2025-05-08T20:43:49.102538Z","iopub.status.idle":"2025-05-08T20:43:51.453524Z","shell.execute_reply.started":"2025-05-08T20:43:49.102520Z","shell.execute_reply":"2025-05-08T20:43:51.452595Z"}},"outputs":[{"name":"stderr","text":"FGSM Attack (ε=0.02): 100%|██████████| 16/16 [00:01<00:00, 11.34it/s]\n100%|██████████| 16/16 [00:00<00:00, 26.53it/s]","output_type":"stream"},{"name":"stdout","text":"\n=== Adversarial Test Set 1 (ε=0.02) ===\nTop-1 Accuracy: 6.20%\nTop-5 Accuracy: 35.40%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## Task 3: Iterative PGD Attack (L∞)\nThis block introduces a multi‑step PGD (Projected Gradient Descent) attack to create **Adversarial Test Set 2**. We split the L∞ budget ε into multiple small steps α, perform gradient ascent and projection back into the ε‑ball at each iteration, then assess the resulting adversarial examples on the same ResNet‑34 model to measure the additional drop in accuracy.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom tqdm import tqdm\n\n# --------- 1. PGD attack function --------- #\ndef pgd_attack(model, x, y, epsilon, alpha, num_steps, clamp_min, clamp_max):\n    \"\"\"\n    Performs a multi-step PGD attack on a batch of inputs.\n\n    Parameters:\n    - model: the evaluation model\n    - x: original inputs, already normalized (tensor of shape [B,3,224,224])\n    - y: true ImageNet labels for each input (tensor of shape [B])\n    - epsilon: L-infinity perturbation budget\n    - alpha: step size for each iteration\n    - num_steps: total number of attack iterations\n    - clamp_min, clamp_max: per-channel lower/upper bounds in normalized space\n\n    Returns:\n    - A tensor of adversarial examples (shape [B,3,224,224])\n    \"\"\"\n    # Create a copy of the input and ensure it is on the correct device\n    x_adv = x.clone().detach().to(device)\n    # Optional random initialization within the epsilon ball:\n    # x_adv = x_adv + torch.empty_like(x_adv).uniform_(-epsilon, epsilon)\n    # x_adv = torch.clamp(x_adv, clamp_min, clamp_max)\n\n    for _ in range(num_steps):\n        x_adv.requires_grad = True\n        outputs = model(x_adv)\n        loss = nn.CrossEntropyLoss()(outputs, y)\n        model.zero_grad()\n        loss.backward()\n        # Compute the sign of the gradient\n        grad_sign = x_adv.grad.sign()\n        # Update adversarial example by a small step in the gradient direction\n        x_adv = x_adv + alpha * grad_sign\n        # Project back into the valid L-infinity ball around the original input\n        x_adv = torch.max(torch.min(x_adv, x + epsilon), x - epsilon)\n        # Clamp to ensure the values remain valid after normalization\n        x_adv = torch.clamp(x_adv, clamp_min, clamp_max).detach()\n\n    return x_adv\n\n# --------- 2. Hyperparameters & precomputations --------- #\nepsilon   = 0.02                      # L-infinity perturbation budget\nnum_steps = 10                        # number of PGD iterations\nalpha     = epsilon / num_steps      # step size per iteration\ndevice    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Normalization mean and std (must match Task 1 preprocessing)\nmean = torch.tensor([0.485, 0.456, 0.406], device=device).view(3, 1, 1)\nstd  = torch.tensor([0.229, 0.224, 0.225], device=device).view(3, 1, 1)\n# Compute min/max values in normalized space corresponding to [0,1] pixel range\nclamp_min = (0.0 - mean) / std\nclamp_max = (1.0 - mean) / std\n\n# --------- 3. Run PGD attack over the test set --------- #\nadv_imgs_2 = []\nadv_lbls_2 = []\n\npretrained_model.eval()\nfor imgs, folder_idxs in tqdm(dataloader, desc=\"PGD Attack\"):\n    imgs = imgs.to(device)\n    # Convert folder index (0–99) to true ImageNet label (0–999)\n    y_true = torch.tensor(\n        [folder_to_imagenet_id[int(i)] for i in folder_idxs],\n        device=device\n    )\n\n    adv_batch = pgd_attack(\n        pretrained_model,\n        imgs,\n        y_true,\n        epsilon,\n        alpha,\n        num_steps,\n        clamp_min,\n        clamp_max\n    )\n\n    adv_imgs_2.append(adv_batch.cpu())\n    adv_lbls_2.append(folder_idxs)  # keep folder indices for evaluation\n\n# Concatenate all adversarial batches and build a DataLoader\nadv_images_2 = torch.cat(adv_imgs_2, dim=0)\nadv_labels_2 = torch.cat(adv_lbls_2, dim=0)\n\nadv_ds_2 = TensorDataset(adv_images_2, adv_labels_2)\nadv_loader_2 = DataLoader(\n    adv_ds_2,\n    batch_size=32,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True\n)\n\n# --------- 4. Evaluate & print results --------- #\nacc2 = evaluate_model(pretrained_model, adv_loader_2, device, top_k=(1, 5))\nprint(f\"\\n=== Adversarial Test Set 2 (PGD ε={epsilon}, steps={num_steps}) ===\")\nprint(f\"Top-1 Accuracy: {acc2[1]:.2f}%\")\nprint(f\"Top-5 Accuracy: {acc2[5]:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T20:43:51.454651Z","iopub.execute_input":"2025-05-08T20:43:51.455275Z","iopub.status.idle":"2025-05-08T20:44:06.810569Z","shell.execute_reply.started":"2025-05-08T20:43:51.455237Z","shell.execute_reply":"2025-05-08T20:44:06.809667Z"}},"outputs":[{"name":"stderr","text":"PGD Attack: 100%|██████████| 16/16 [00:14<00:00,  1.10it/s]\n100%|██████████| 16/16 [00:00<00:00, 25.57it/s]","output_type":"stream"},{"name":"stdout","text":"\n=== Adversarial Test Set 2 (PGD ε=0.02, steps=10) ===\nTop-1 Accuracy: 0.20%\nTop-5 Accuracy: 14.00%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## Task 4: Patch‑PGD Attack\nIn this section, we constrain the PGD attack to a single fixed square patch (e.g., 64×64) in the image center, generating **Adversarial Test Set 3**. By iteratively optimizing the perturbation only within that patch and projecting back into the local ε‑ball, we demonstrate how localized attacks can still significantly reduce model accuracy.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom tqdm import tqdm\n\n# --------- 1. Patch‑PGD attack function --------- #\ndef patch_pgd_attack(model, x, y, epsilon, alpha, num_steps, patch_size, clamp_min, clamp_max):\n    \"\"\"\n    Performs a PGD attack confined to the central patch of each image.\n\n    Parameters:\n    - model: the evaluation model\n    - x: original inputs, already normalized (tensor of shape [B,3,224,224])\n    - y: true ImageNet labels for each input (tensor of shape [B])\n    - epsilon: L-infinity perturbation budget\n    - alpha: step size for each PGD iteration\n    - num_steps: number of attack iterations\n    - patch_size: size of the square patch (in pixels)\n    - clamp_min, clamp_max: per-channel bounds in normalized space\n\n    Returns:\n    - A tensor of adversarial examples (shape [B,3,224,224])\n    \"\"\"\n    B, C, H, W = x.shape\n\n    # Compute coordinates for a central patch\n    top  = (H - patch_size) // 2\n    left = (W - patch_size) // 2\n\n    # Create a mask that is 1 inside the patch, 0 elsewhere\n    mask = torch.zeros_like(x)\n    mask[:, :, top:top+patch_size, left:left+patch_size] = 1.0\n    mask = mask.to(x.device)\n\n    # Clone the original input for projection reference\n    x_adv  = x.clone().detach()\n    x_orig = x.clone().detach()\n\n    for _ in range(num_steps):\n        # Enable gradient computation on adversarial tensor\n        x_adv.requires_grad = True\n\n        # Forward and backward pass\n        outputs = model(x_adv)\n        loss    = nn.CrossEntropyLoss()(outputs, y)\n        model.zero_grad()\n        loss.backward()\n\n        # Take a step of size alpha in the sign gradient direction within the patch\n        grad_sign = x_adv.grad.sign()\n        x_adv = x_adv + alpha * grad_sign * mask\n\n        # Project back to ensure perturbation stays within L_inf ball of radius epsilon\n        x_adv = torch.max(torch.min(x_adv, x_orig + epsilon), x_orig - epsilon)\n        # Finally clamp to valid normalized pixel range\n        x_adv = torch.clamp(x_adv, clamp_min, clamp_max).detach()\n\n    return x_adv\n\n# --------- 2. Hyperparameters & precomputations --------- #\ndevice      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nepsilon     = 1.0       # L-infinity budget (can also try other values)\nnum_steps   = 30        # number of PGD iterations\nalpha       = epsilon / num_steps  # step size per iteration\npatch_size  = 64        # side length of the square patch\n\n# Reuse normalization parameters from Task 1/2\nmean = torch.tensor([0.485, 0.456, 0.406], device=device).view(3,1,1)\nstd  = torch.tensor([0.229, 0.224, 0.225], device=device).view(3,1,1)\n# Compute normalized pixel bounds corresponding to [0,1]\nclamp_min = (0.0 - mean) / std\nclamp_max = (1.0 - mean) / std\n\n# --------- 3. Build adversarial set & evaluate --------- #\nadv_imgs_3 = []\nadv_lbls_3 = []\n\npretrained_model.eval()\nfor imgs, folder_idxs in tqdm(dataloader, desc=\"Patch‑PGD Attack\"):\n    imgs = imgs.to(device)\n    # Convert folder index to true ImageNet label\n    y_true = torch.tensor(\n        [folder_to_imagenet_id[int(i)] for i in folder_idxs],\n        device=device\n    )\n\n    # Generate patch-based adversarial examples\n    adv_batch = patch_pgd_attack(\n        pretrained_model,\n        imgs,\n        y_true,\n        epsilon,\n        alpha,\n        num_steps,\n        patch_size,\n        clamp_min,\n        clamp_max\n    )\n\n    adv_imgs_3.append(adv_batch.cpu())\n    adv_lbls_3.append(folder_idxs)\n\n# Concatenate all adversarial samples and create a DataLoader\nadv_images_3 = torch.cat(adv_imgs_3, dim=0)\nadv_labels_3 = torch.cat(adv_lbls_3, dim=0)\nadv_ds_3     = TensorDataset(adv_images_3, adv_labels_3)\nadv_loader_3 = DataLoader(\n    adv_ds_3,\n    batch_size=32,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True\n)\n\n# --------- 4. Evaluate & print results --------- #\nacc3 = evaluate_model(pretrained_model, adv_loader_3, device, top_k=(1,5))\nprint(f\"\\n=== Adversarial Test Set 3 (Patch‑PGD ε={epsilon}, steps={num_steps}, patch size={patch_size}) ===\")\nprint(f\"Top‑1 Accuracy: {acc3[1]:.2f}%\")\nprint(f\"Top‑5 Accuracy: {acc3[5]:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T20:44:06.811613Z","iopub.execute_input":"2025-05-08T20:44:06.811848Z","iopub.status.idle":"2025-05-08T20:44:49.029649Z","shell.execute_reply.started":"2025-05-08T20:44:06.811825Z","shell.execute_reply":"2025-05-08T20:44:49.028723Z"}},"outputs":[{"name":"stderr","text":"Patch‑PGD Attack: 100%|██████████| 16/16 [00:41<00:00,  2.59s/it]\n100%|██████████| 16/16 [00:00<00:00, 25.04it/s]","output_type":"stream"},{"name":"stdout","text":"\n=== Adversarial Test Set 3 (Patch‑PGD ε=1.0, steps=30, patch size=64) ===\nTop‑1 Accuracy: 0.60%\nTop‑5 Accuracy: 20.20%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## Task 5: Transferability Evaluation on DenseNet‑121\nFinally, we load a different pre‑trained network (DenseNet‑121) to test the transferability of all four datasets (original + three adversarial sets). We reuse the same `evaluate_model` function to report top‑1 and top‑5 accuracy for each DataLoader, summarize the results in a table, and analyze cross‑model vulnerability.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch.utils.data import DataLoader\n\n# --------- 1. Load new pre-trained model --------- #\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nnew_model = torchvision.models.densenet121(weights='IMAGENET1K_V1')\nnew_model = new_model.to(device)\nnew_model.eval()\n\n# --------- 2. Prepare four DataLoaders --------- #\n# Assume the following variables have been defined:\n#   dataloader     # DataLoader for the original test set\n#   adv_loader     # DataLoader for Adversarial Test Set 1 (FGSM)\n#   adv_loader_2   # DataLoader for Adversarial Test Set 2 (PGD)\n#   adv_loader_3   # DataLoader for Adversarial Test Set 3 (Patch-PGD)\n\nloaders = [\n    (\"Original Test Set\", dataloader),\n    (\"Adv Test Set 1 (FGSM)\", adv_loader),\n    (\"Adv Test Set 2 (PGD)\", adv_loader_2),\n    (\"Adv Test Set 3 (Patch-PGD)\", adv_loader_3),\n]\n\n# --------- 3. Evaluate all datasets on the new model --------- #\nresults = {}\nfor name, loader in loaders:\n    acc = evaluate_model(new_model, loader, device, top_k=(1, 5))\n    results[name] = acc\n    print(f\"{name}: Top-1 = {acc[1]:.2f}%, Top-5 = {acc[5]:.2f}%\")\n\n# --------- 4. (Optional) Aggregate results into a table --------- #\n# If you want to organize the results into a DataFrame for easy printing or saving:\nimport pandas as pd\n\ndf = pd.DataFrame.from_dict(results, orient='index')\ndf.columns = ['Top-1 (%)', 'Top-5 (%)']\nprint(\"\\nSummary:\")\nprint(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T20:44:49.031623Z","iopub.execute_input":"2025-05-08T20:44:49.032355Z","iopub.status.idle":"2025-05-08T20:44:54.384689Z","shell.execute_reply.started":"2025-05-08T20:44:49.032323Z","shell.execute_reply":"2025-05-08T20:44:54.383715Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 16/16 [00:01<00:00,  8.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Original Test Set: Top-1 = 74.80%, Top-5 = 93.60%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 16/16 [00:01<00:00, 15.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adv Test Set 1 (FGSM): Top-1 = 63.40%, Top-5 = 89.40%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 16/16 [00:01<00:00, 15.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adv Test Set 2 (PGD): Top-1 = 64.00%, Top-5 = 90.80%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 16/16 [00:01<00:00, 15.26it/s]","output_type":"stream"},{"name":"stdout","text":"Adv Test Set 3 (Patch-PGD): Top-1 = 60.60%, Top-5 = 89.00%\n\nSummary:\n                            Top-1 (%)  Top-5 (%)\nOriginal Test Set                74.8       93.6\nAdv Test Set 1 (FGSM)            63.4       89.4\nAdv Test Set 2 (PGD)             64.0       90.8\nAdv Test Set 3 (Patch-PGD)       60.6       89.0\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## Findings & Trends\n- **Degradation Across Attacks**  \n  On DenseNet‑121, all three adversarial sets generated against ResNet‑34 still significantly reduce accuracy. The original Top‑1/Top‑5 of **74.8%/93.6%** falls to:  \n  - **FGSM (ε=0.02):** 63.4% / 89.4%  \n  - **PGD (ε=0.02, steps=10):** 64.0% / 90.8%  \n  - **Patch‑PGD (ε=1, steps=30, patch_size=64):** 60.6% / 89.0%\n\n- **Relative Strength**  \n  - Patch‑based PGD yields the largest Top‑1 drop (~ 14.2 pp) and Top‑5 drop (~ 4.6 pp).  \n  - Multi‑step PGD only marginally outperforms single‑step FGSM in black‑box transfer.\n\n- **Transferability Plateau**  \n  Despite white‑box PGD being very strong on ResNet‑34, its **black‑box** effect on DenseNet‑121 saturates around 60–65% Top‑1. More aggressive attacks on ResNet‑34 give diminishing returns when transferred.\n\n","metadata":{}},{"cell_type":"markdown","source":"## Lessons Learned\n1. **Cross‑Model Generalization**  \n   Adversarial examples crafted on one architecture often transfer to others, but with reduced potency.  \n2. **Simplicity Suffices**  \n   Even simple FGSM attacks can induce large drops in unseen models, so computationally cheap attacks can be effective in transfer settings.  \n3. **Patch Concentration**  \n   Focused perturbations (patch‑based) in discriminative regions can amplify transfer success.  \n4. **Cost vs. Benefit**  \n   Iterative methods (PGD) yield slightly stronger transfer than FGSM, but the extra compute may not be justified by the marginal accuracy drop.\n\n","metadata":{}},{"cell_type":"markdown","source":"## Mitigating Transferability\n- **Adversarial Training with Ensembles**  \n  Train on adversarial examples from multiple source models (ResNet, DenseNet, etc.) to build broader robustness.\n- **Input Randomization & Preprocessing**  \n  Apply random resizing, cropping, JPEG compression, or bit‑depth reduction to disrupt precise perturbations.\n- **Ensemble Defenses**  \n  Aggregate predictions across diverse models to dilute attack effectiveness from any single surrogate.\n- **Certified Defenses**  \n  Use approaches like randomized smoothing to provide provable ℓ₂‑bounded robustness, which also reduces ℓ∞ transferability.\n\n","metadata":{}}]}